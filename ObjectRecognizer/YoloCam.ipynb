{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import carla\n",
    "import math\n",
    "import random\n",
    "import time\n",
    "import queue\n",
    "import numpy as np\n",
    "import cv2\n",
    "import subprocess\n",
    "import os\n",
    "from image_label_generator import ImageLabelGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "subprocess.run('taskkill /f /fi \"IMAGENAME eq CarlaUE4*\"', shell=True)\n",
    "os.startfile(\"\"\"C:\\carla\\CarlaUE4_Low\"\"\")\n",
    "start = input(\"Pressione enter para iniciar\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "client = carla.Client('localhost', 2000)\n",
    "client.set_timeout(50.0) # seconds\n",
    "world  = client.load_world('Town01')\n",
    "bp_lib = world.get_blueprint_library()\n",
    "\n",
    "# get possible spawn points\n",
    "current_map = world.get_map()\n",
    "\n",
    "# spawn_transforms will be a list of carla.Transform\n",
    "spawn_points = current_map.get_spawn_points()\n",
    "\n",
    "# spawn vehicle\n",
    "vehicle_bp =bp_lib.find('vehicle.lincoln.mkz_2020')\n",
    "vehicle = world.try_spawn_actor(vehicle_bp, spawn_points[0])\n",
    "\n",
    "\n",
    "# # Create a queue to store and retrieve the sensor data\n",
    "# image_queue = queue.Queue()\n",
    "# camera.listen(image_queue.put)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # spawn camera\n",
    "camera_bp = bp_lib.find('sensor.camera.rgb')\n",
    "camera_init_trans = carla.Transform(carla.Location(z=2))\n",
    "camera = world.spawn_actor(camera_bp, camera_init_trans, attach_to=vehicle)\n",
    "vehicle.set_autopilot(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "273"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # Set up the simulator in synchronous mode\n",
    "settings = world.get_settings()\n",
    "settings.synchronous_mode = True # Enables synchronous mode\n",
    "settings.fixed_delta_seconds = 0.05\n",
    "world.apply_settings(settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create a queue to store and retrieve the sensor data\n",
    "image_queue = queue.Queue()\n",
    "camera.listen(image_queue.put)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### FUNCTINOS THAT CONVERT 3D POINTS INTO CAMERA POINTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_projection_matrix(w, h, fov):\n",
    "    focal = w / (2.0 * np.tan(fov * np.pi / 360.0))\n",
    "    K = np.identity(3)\n",
    "    K[0, 0] = K[1, 1] = focal\n",
    "    K[0, 2] = w / 2.0\n",
    "    K[1, 2] = h / 2.0\n",
    "    return K\n",
    "\n",
    "def get_image_point(loc, K, w2c):\n",
    "        # Calculate 2D projection of 3D coordinate\n",
    "\n",
    "        # Format the input coordinate (loc is a carla.Position object)\n",
    "        point = np.array([loc.x, loc.y, loc.z, 1])\n",
    "        # transform to camera coordinates\n",
    "        point_camera = np.dot(w2c, point)\n",
    "\n",
    "        # New we must change from UE4's coordinate system to an \"standard\"\n",
    "        # (x, y ,z) -> (y, -z, x)\n",
    "        # and we remove the fourth componebonent also\n",
    "        point_camera = [point_camera[1], -point_camera[2], point_camera[0]]\n",
    "\n",
    "        # now project 3D->2D using the camera matrix\n",
    "        point_img = np.dot(K, point_camera)\n",
    "        # normalize\n",
    "        point_img[0] /= point_img[2]\n",
    "        point_img[1] /= point_img[2]\n",
    "\n",
    "        return point_img[0:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CALCULATING THE CAMERA PROJECTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Get the world to camera matrix\n",
    "world_2_camera = np.array(camera.get_transform().get_inverse_matrix())\n",
    "\n",
    "# Get the attributes from the camera\n",
    "image_w = camera_bp.get_attribute(\"image_size_x\").as_int()\n",
    "image_h = camera_bp.get_attribute(\"image_size_y\").as_int()\n",
    "fov = camera_bp.get_attribute(\"fov\").as_float()\n",
    "\n",
    "# Calculate the camera projection matrix to project from 3D -> 2D\n",
    "K = build_projection_matrix(image_w, image_h, fov)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GETTING THE BOUNDING BOXES\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mO Kernel deu pane ao executar o código na célula atual ou em uma célula anterior. \n",
      "\u001b[1;31mAnalise o código nas células para identificar uma possível causa da pane. \n",
      "\u001b[1;31mClique <a href='https://aka.ms/vscodeJupyterKernelCrash'>aqui</a> para obter mais informações. \n",
      "\u001b[1;31mConsulte Jupyter <a href='command:jupyter.viewOutput'>log</a> para obter mais detalhes."
     ]
    }
   ],
   "source": [
    "image_label_gen = ImageLabelGenerator(camera, world, 25)\n",
    "world.tick()\n",
    "image_label_gen.get_image_and_create_copy_zeros_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mO Kernel deu pane ao executar o código na célula atual ou em uma célula anterior. \n",
      "\u001b[1;31mAnalise o código nas células para identificar uma possível causa da pane. \n",
      "\u001b[1;31mClique <a href='https://aka.ms/vscodeJupyterKernelCrash'>aqui</a> para obter mais informações. \n",
      "\u001b[1;31mConsulte Jupyter <a href='command:jupyter.viewOutput'>log</a> para obter mais detalhes."
     ]
    }
   ],
   "source": [
    "image_label_gen = ImageLabelGenerator(camera, world, 25)\n",
    "while True:\n",
    "    \n",
    "    # Retrieve and reshape the image\n",
    "    world.tick()\n",
    "    new_matrix, exists_object, img = image_label_gen.create_label_matrix()\n",
    "    if exists_object:\n",
    "        print(new_matrix)\n",
    "        cv2.imshow('ImageWindowName',img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_22664\\1160922286.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[1;31m# Retrieve and reshape the image\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0mworld\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtick\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m     \u001b[0mimage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimage_queue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraw_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mheight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwidth\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\victo\\anaconda3\\envs\\CarlaVenv\\lib\\queue.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(self, block, timeout)\u001b[0m\n\u001b[0;32m    168\u001b[0m             \u001b[1;32melif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    169\u001b[0m                 \u001b[1;32mwhile\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_qsize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 170\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnot_empty\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    171\u001b[0m             \u001b[1;32melif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    172\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"'timeout' must be a non-negative number\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\victo\\anaconda3\\envs\\CarlaVenv\\lib\\threading.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    294\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m    \u001b[1;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    295\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 296\u001b[1;33m                 \u001b[0mwaiter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    297\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    298\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "bounding_box_set = world.get_level_bbs(carla.CityObjectLabel.TrafficLight)\n",
    "bounding_box_set.extend(world.get_level_bbs(carla.CityObjectLabel.TrafficSigns))\n",
    "\n",
    "objects = world.get_environment_objects(carla.CityObjectLabel.TrafficLight)\n",
    "objects.extend(world.get_environment_objects(carla.CityObjectLabel.TrafficSigns))\n",
    "edges = [[0,1], [1,3], [3,2], [2,0], [0,4], [4,5], [5,1], [5,7], [7,6], [6,4], [6,2], [7,3]]\n",
    "image_label_gen = ImageLabelGenerator(camera, world, 25)\n",
    "while True:\n",
    "    \n",
    "    # Retrieve and reshape the image\n",
    "    world.tick()\n",
    "    image = image_queue.get()\n",
    "\n",
    "    img = np.reshape(np.copy(image.raw_data), (image.height, image.width, 4))\n",
    "\n",
    "    # Get the camera matrix \n",
    "    world_2_camera = np.array(camera.get_transform().get_inverse_matrix())\n",
    "\n",
    "    for _object in objects:\n",
    "        \n",
    "        bb = _object.bounding_box\n",
    "        dist = _object.transform.location.distance(camera.get_transform().location)\n",
    "\n",
    "        # Filter for the vehicles within 50m\n",
    "        if dist < 25:\n",
    "\n",
    "        # Calculate the dot product between the forward vector\n",
    "        # of the vehicle and the vector between the vehicle\n",
    "        # and the other vehicle. We threshold this dot product\n",
    "        # to limit to drawing bounding boxes IN FRONT OF THE CAMERA\n",
    "            forward_vec = camera.get_transform().get_forward_vector()\n",
    "            ray = _object.transform.location - camera.get_transform().location\n",
    "\n",
    "            if forward_vec.dot(ray) > 1:\n",
    "                p1 = get_image_point(bb.location, K, world_2_camera)\n",
    "                verts = [v for v in bb.get_world_vertices(carla.Transform())]\n",
    "                x_max = -10000\n",
    "                x_min = 10000\n",
    "                y_max = -10000\n",
    "                y_min = 10000\n",
    "\n",
    "                for vert in verts:\n",
    "                    p = get_image_point(vert, K, world_2_camera)\n",
    "                    # Find the rightmost vertex\n",
    "                    if p[0] > x_max:\n",
    "                        x_max = p[0]\n",
    "                    # Find the leftmost vertex\n",
    "                    if p[0] < x_min:\n",
    "                        x_min = p[0]\n",
    "                    # Find the highest vertex\n",
    "                    if p[1] > y_max:\n",
    "                        y_max = p[1]\n",
    "                    # Find the lowest  vertex\n",
    "                    if p[1] < y_min:\n",
    "                        y_min = p[1]\n",
    "\n",
    "                cv2.line(img, (int(x_min),int(y_min)), (int(x_max),int(y_min)), (0,0,255, 255), 1)\n",
    "                cv2.line(img, (int(x_min),int(y_max)), (int(x_max),int(y_max)), (0,0,255, 255), 1)\n",
    "                cv2.line(img, (int(x_min),int(y_min)), (int(x_min),int(y_max)), (0,0,255, 255), 1)\n",
    "                cv2.line(img, (int(x_max),int(y_min)), (int(x_max),int(y_max)), (0,0,255, 255), 1)\n",
    "                try:\n",
    "                    np.savetxt('imagem.csv')\n",
    "                except:\n",
    "                    pass\n",
    "\n",
    "\n",
    "    cv2.imshow('ImageWindowName',img)\n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        break\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mO Kernel deu pane ao executar o código na célula atual ou em uma célula anterior. \n",
      "\u001b[1;31mAnalise o código nas células para identificar uma possível causa da pane. \n",
      "\u001b[1;31mClique <a href='https://aka.ms/vscodeJupyterKernelCrash'>aqui</a> para obter mais informações. \n",
      "\u001b[1;31mConsulte Jupyter <a href='command:jupyter.viewOutput'>log</a> para obter mais detalhes."
     ]
    }
   ],
   "source": [
    "# Retrieve and reshape the image\n",
    "bounding_box_set = world.get_level_bbs(carla.CityObjectLabel.TrafficLight)\n",
    "bounding_box_set.extend(world.get_level_bbs(carla.CityObjectLabel.TrafficSigns))\n",
    "\n",
    "objects = world.get_environment_objects(carla.CityObjectLabel.TrafficLight)\n",
    "objects.extend(world.get_environment_objects(carla.CityObjectLabel.TrafficSigns))\n",
    "edges = [[0,1], [1,3], [3,2], [2,0], [0,4], [4,5], [5,1], [5,7], [7,6], [6,4], [6,2], [7,3]]\n",
    "\n",
    "world.tick()\n",
    "image = image_queue.get()\n",
    "\n",
    "img = np.reshape(np.copy(image.raw_data), (image.height, image.width, 4))\n",
    "\n",
    "# Get the camera matrix \n",
    "world_2_camera = np.array(camera.get_transform().get_inverse_matrix())\n",
    "\n",
    "for _object in objects:\n",
    "    \n",
    "    bb = _object.bounding_box\n",
    "    dist = _object.transform.location.distance(vehicle.get_transform().location)\n",
    "\n",
    "    # Filter for the vehicles within 50m\n",
    "    if dist < 25:\n",
    "\n",
    "    # Calculate the dot product between the forward vector\n",
    "    # of the vehicle and the vector between the vehicle\n",
    "    # and the other vehicle. We threshold this dot product\n",
    "    # to limit to drawing bounding boxes IN FRONT OF THE CAMERA\n",
    "        forward_vec = vehicle.get_transform().get_forward_vector()\n",
    "        ray = _object.transform.location - vehicle.get_transform().location\n",
    "\n",
    "        if forward_vec.dot(ray) > 1:\n",
    "            p1 = get_image_point(bb.location, K, world_2_camera)\n",
    "            verts = [v for v in bb.get_world_vertices(_object.transform)]\n",
    "            x_max = -10000\n",
    "            x_min = 10000\n",
    "            y_max = -10000\n",
    "            y_min = 10000\n",
    "\n",
    "            for vert in verts:\n",
    "                p = get_image_point(vert, K, world_2_camera)\n",
    "                # Find the rightmost vertex\n",
    "                if p[0] > x_max:\n",
    "                    x_max = p[0]\n",
    "                # Find the leftmost vertex\n",
    "                if p[0] < x_min:\n",
    "                    x_min = p[0]\n",
    "                # Find the highest vertex\n",
    "                if p[1] > y_max:\n",
    "                    y_max = p[1]\n",
    "                # Find the lowest  vertex\n",
    "                if p[1] < y_min:\n",
    "                    y_min = p[1]\n",
    "\n",
    "            cv2.line(img, (int(x_min),int(y_min)), (int(x_max),int(y_min)), (0,0,255, 255), 1)\n",
    "            cv2.line(img, (int(x_min),int(y_max)), (int(x_max),int(y_max)), (0,0,255, 255), 1)\n",
    "            cv2.line(img, (int(x_min),int(y_min)), (int(x_min),int(y_max)), (0,0,255, 255), 1)\n",
    "            cv2.line(img, (int(x_max),int(y_min)), (int(x_max),int(y_max)), (0,0,255, 255), 1)\n",
    "            try:\n",
    "                np.savetxt('imagem.csv')\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "cv2.imshow('ImageWindowName',img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CarlaVenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
